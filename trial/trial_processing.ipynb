{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "upset-serbia",
   "metadata": {},
   "source": [
    "**The purpose of this notebook is to organize the results from all trials, (each stored in its own dictionary), and consolidate them into a numpy array containing the statistics of all trials for a specific set of parameter settings (e.g. gamma = 10^-4 ~ 10^8 @ noise=0.3, two 5-unit hidden layers)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "manufactured-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "#system dependent. Add the dictionaries to the path.\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "import math as m\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "liquid-start",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a whole bunch of parameters\n",
    "spy = 60 * 60 * 24 * 365.25\n",
    "rhoi = 910.\n",
    "rhow = 1028.\n",
    "delta = 1. - rhoi / rhow\n",
    "g = 9.81\n",
    "a = 0.3 / spy\n",
    "Q0 = 4.0e5 / spy\n",
    "H0 = 1.0e3\n",
    "B0 = 1.4688e8\n",
    "n = 3\n",
    "\n",
    "# Set scalings\n",
    "Z0 = a ** (1/(n+1)) * (4 * B0) ** (n / (n + 1)) / (rhoi * g * delta) ** (n/(n + 1))\n",
    "U0 = 400 / spy\n",
    "Lx = U0 * Z0 / a\n",
    "h0 = H0 / Z0; q0 = Q0 / (U0 * Z0)\n",
    "nu_star = (2 * B0) / ( rhoi * g * delta * Z0) * (U0 / Lx) ** (1 / n)\n",
    "A0 = (a * Lx) / (U0 * Z0)\n",
    "\n",
    "def analytic_h_constantB(x):\n",
    "    return ((A0 * h0 ** (n + 1) * (A0 * x + q0) ** (n + 1)) / (\n",
    "            A0 * q0 ** (n + 1) - (q0 * h0) ** (n + 1) + (h0 * (A0 * x + q0)) ** (n + 1))) ** (1 / (n + 1))\n",
    "\n",
    "def analytic_u_constantB(x):\n",
    "    return (A0 * x + q0) / analytic_h_constantB(x)\n",
    "\n",
    "x_star = np.linspace(start = 0.0, stop = 1.0, num = 401)\n",
    "\n",
    "def compute_uerr(u_pred):\n",
    "    return np.mean(np.square(u_pred-analytic_u_constantB(x_star)))\n",
    "\n",
    "def compute_herr(h_pred):\n",
    "    return np.mean(np.square(h_pred-analytic_h_constantB(x_star)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-blair",
   "metadata": {},
   "source": [
    "**1) Reload compressed result dictionaries from a set of trials into python dictionaries. We temporarily store results from separate trials into individual dictionaries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "amino-checklist",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 501/501 [00:01<00:00, 500.04it/s]\n"
     ]
    }
   ],
   "source": [
    "num_trial_list = [501] #number of trials for each set of results being loaded\n",
    "path_list = ['n3_log_gamma/r'] # the folder where all result dictionaries are stored, plus the \"file prefix\" of the results\n",
    "# e.g. if the result dictionaries are named 1st trial = 'r1', 2nd trial = 'r2', pass in /result_folder/r \n",
    "\n",
    "dictstr_list = ['n3r'] #choose the prefix you want to call your loaded results. e.g. with this setting the resulting dictionaries \n",
    "#will be called n3r1 (first trial result), n3r2 (second trial result), etc\n",
    "\n",
    "for i in range(len(path_list)):\n",
    "    num_trials = num_trial_list[i]\n",
    "    dictstr = dictstr_list[i]\n",
    "    path = path_list[i]\n",
    "    \n",
    "    for j in tqdm(range(num_trials)):\n",
    "        exec(f\"{dictstr}r{j} = loadmat('{path}{j}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-vessel",
   "metadata": {},
   "source": [
    "**2) Combine results from a set of trials into a numpy array. We define two helper functions. 'error_array()' creates numpy arrays of average prediction error for all trials, with separate columns for error in u,h, and B. deviation_array() performs a similar operation but for u-deviation and h-deviation (see paper for definitions.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automotive-infrared",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_array(g_index, exp, num_trials): #specify index of gamma-value, and name of the experiment (dictstr)\n",
    "    u_errs = []\n",
    "    h_errs = []\n",
    "    b_errs = []\n",
    "    \n",
    "    for i in range(num_trials):\n",
    "        exec(f\"u_errs.append(compute_uerr({exp}r{i}['u_p'][{g_index}]))\")\n",
    "        exec(f\"h_errs.append(compute_herr({exp}r{i}['h_p'][{g_index}]))\")\n",
    "        exec(f\"b_errs.append({exp}r{i}['berrs'][0][{g_index}])\")\n",
    "\n",
    "    u_errs = np.asarray(u_errs)\n",
    "    h_errs = np.asarray(h_errs)\n",
    "    b_errs = np.asarray(b_errs)\n",
    "    \n",
    "    return u_errs, h_errs, b_errs\n",
    "\n",
    "def deviation_array(g_index, exp, num_trials): #specify index of gamma-value, and name of the experiment (dictstr)\n",
    "    u_devs = []\n",
    "    h_devs = []\n",
    "    b_errs = []\n",
    "    \n",
    "#return np.mean(np.square(u_pred-analytic_u_constantB(x_star)))\n",
    "\n",
    "    for i in range(num_trials):\n",
    "        exec(f\"u_devs.append(np.mean(np.square(({exp}r{i}['u_p'][{g_index}]-{exp}r{i}['u_sampled'][{g_index}]))))\")\n",
    "        exec(f\"h_devs.append(np.mean(np.square(({exp}r{i}['h_p'][{g_index}]-{exp}r{i}['h_sampled'][{g_index}]))))\")\n",
    "        exec(f\"b_errs.append({exp}r{i}['berrs'][0][{g_index}])\")\n",
    "\n",
    "    u_devs = np.asarray(u_devs)\n",
    "    h_devs = np.asarray(h_devs)\n",
    "    b_errs = np.asarray(b_errs)\n",
    "    \n",
    "    return u_devs, h_devs, b_errs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chemical-kelly",
   "metadata": {},
   "source": [
    "**Example code for a set of trials with noise = 0.3 and 13 values of gamma. Replace arguments of \"error_array\" and \"deviation_array\" with the dictionary prefix of the desired set of trials.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infinite-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_num = 501 #number of trials\n",
    "gamma_num = 13 # number of gamma values tested\n",
    "set_name = 'n3' #dictionary prefix for desired set of trials\n",
    "\n",
    "#Create a 13 (gamma values) by 3 (variables) by 501 (trials) numpy array.\n",
    "n3_errs = np.zeros(shape = (gamma_num,3,trial_num))\n",
    "for i in range(13):\n",
    "    u_errs, h_errs, b_errs = error_array(i,set_name,trial_num)\n",
    "    n2_errs[i][0] = u_errs\n",
    "    n2_errs[i][1] = h_errs\n",
    "    n2_errs[i][2] = b_errs\n",
    "np.save('n3_errs.npy', n3_errs)\n",
    "\n",
    "n3_devs = np.zeros(shape = (13,3,501))\n",
    "for i in range(13):\n",
    "    u_devs, h_devs, b_errs = deviation_array(i,set_name,trial_num)\n",
    "    n3_devs[i][0] = u_devs\n",
    "    n3_devs[i][1] = h_devs\n",
    "    n3_devs[i][2] = b_errs\n",
    "np.save('n3_devs.npy', n3_devs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "classical-daughter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stunning-combination",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
